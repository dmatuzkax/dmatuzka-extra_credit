{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7664616-bcb4-4ceb-b40b-966b57371e6d",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2132580-2593-46f3-bfcb-6bc3f625ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d331f7a-ef0e-49c9-a343-f137c49e9b4a",
   "metadata": {},
   "source": [
    "# Loading the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70507d4a-8975-49a4-98af-9635569d680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape is  (370703, 24)\n",
      "test.csv shape is  (92676, 23)\n",
      "\n",
      "        id                         trans_num  trans_date trans_time  \\\n",
      "0   308467  26ad750c2ff71f32631b58913582d70a  2024-01-10   06:49:39   \n",
      "1   261578  fea9c1efe3f2b97f27ad0ab5409ec861  2024-01-06   02:37:50   \n",
      "2      341  2ae350b982be840f3666273e0c2f3a05  2024-01-18   21:40:21   \n",
      "3  1147639  bbdd8adfc0a34ed0e817f809193c85c0  2024-01-21   16:20:15   \n",
      "4   314152  fc7756004dc2a9bc450eb894a670b804  2024-01-21   19:36:26   \n",
      "\n",
      "    unix_time        category     amt            cc_num    first     last  \\\n",
      "0  1704887379        misc_pos  188.38      676355457570   Andrea  Johnson   \n",
      "1  1704526670     grocery_pos  102.63   377178373574671   Rhonda   Chavez   \n",
      "2  1705632021   entertainment    1.62  3599292013370451  Stephen     Khan   \n",
      "3  1705872015  health_fitness    5.64  3594292572430345   Justin   Reilly   \n",
      "4  1705883786  health_fitness   97.09  4867547663675548    Alice   Duarte   \n",
      "\n",
      "   ...    zip      lat      long city_pop                          job  \\\n",
      "0  ...  62220  38.5127  -89.9847    95666        Accounting technician   \n",
      "1  ...  21784  39.4567  -76.9696    37941            Designer, graphic   \n",
      "2  ...  49735  45.0125  -84.6723    19515  Careers information officer   \n",
      "3  ...  44256  41.1404  -81.8584    62039         Merchandiser, retail   \n",
      "4  ...  91501  34.1862 -118.3009   106841               Prison officer   \n",
      "\n",
      "          dob                          merchant  merch_lat  merch_long  \\\n",
      "0  1983-05-26          fraud_Turcotte-Halvorson  39.268874  -89.273447   \n",
      "1  1976-12-03         fraud_Schamberger-O'Keefe  39.961495  -76.707640   \n",
      "2  1999-08-24  fraud_Nicolas, Hills and McGlynn  44.393561  -85.342323   \n",
      "3  1930-02-24                 fraud_Cormier LLC  40.283764  -81.639361   \n",
      "4  1951-10-15                 fraud_Kulas Group  35.149704 -118.087440   \n",
      "\n",
      "  is_fraud  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "       id                         trans_num  trans_date trans_time  \\\n",
      "0   52329  2e6b34f2047158280fd5b50cb5249fcc  2024-01-27   13:17:44   \n",
      "1   92215  5e4c36e1e6f1838f0afe1ed83d42d48e  2024-01-31   21:12:51   \n",
      "2  107070  de58b3413be0b956c261b8e756006b5d  2024-01-24   23:06:59   \n",
      "3  117508  63e5e8954b6954121fb9395b8fb87ec3  2024-01-15   14:42:37   \n",
      "4  525132  f0acdc291ca35b61a873060e419b20a5  2024-01-30   22:02:41   \n",
      "\n",
      "    unix_time       category     amt            cc_num    first     last  ...  \\\n",
      "0  1706379464      kids_pets   13.00    30184874050384   Edward  Mueller  ...   \n",
      "1  1706753571         travel   25.64  3560293989785735     Ryan   Reeves  ...   \n",
      "2  1706155619           home   99.48   213175392060268  Gregory   Graham  ...   \n",
      "3  1705347757    grocery_pos  972.26  2720994415033785  Jessica    Carey  ...   \n",
      "4  1706670161  personal_care  165.04      639070744995    Corey   Rogers  ...   \n",
      "\n",
      "  state    zip      lat      long  city_pop  \\\n",
      "0    NY  11230  40.6225  -73.9650   2504700   \n",
      "1    CA  92504  33.9315 -117.4119    419138   \n",
      "2    KY  42629  36.9680  -85.0968      4953   \n",
      "3    TX  75571  33.1808  -94.7639      2846   \n",
      "4    NJ   7022  40.8170  -74.0000     13835   \n",
      "\n",
      "                                    job         dob  \\\n",
      "0                Leisure centre manager  1955-12-17   \n",
      "1                             Mudlogger  1940-06-22   \n",
      "2                  Engineer, automotive  1993-03-18   \n",
      "3       Geophysicist/field seismologist  1958-06-30   \n",
      "4  Accountant, chartered public finance  1972-04-13   \n",
      "\n",
      "                             merchant  merch_lat  merch_long  \n",
      "0     fraud_Lowe, Dietrich and Erdman  40.707029  -74.027386  \n",
      "1               fraud_Johnston-Casper  34.344545 -117.348319  \n",
      "2  fraud_Gutmann, McLaughlin and Wiza  37.493843  -85.224136  \n",
      "3   fraud_Schoen, Kuphal and Nitzsche  32.238558  -94.085343  \n",
      "4                fraud_Sporer-Keebler  40.957527  -73.328707  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "                 id     unix_time            amt        cc_num            zip  \\\n",
      "count  3.707030e+05  3.707030e+05  370703.000000  3.707030e+05  370703.000000   \n",
      "mean   4.080297e+05  1.705433e+09     123.499358  3.862304e+17   51525.494701   \n",
      "std    3.361065e+05  7.615549e+05     244.813193  1.260746e+18   29974.830535   \n",
      "min    0.000000e+00  1.704085e+09       1.000000  6.040027e+10    1001.000000   \n",
      "25%    1.325125e+05  1.704729e+09      12.360000  1.800195e+14   27705.000000   \n",
      "50%    3.162290e+05  1.705435e+09      52.210000  3.513445e+15   48214.000000   \n",
      "75%    6.121395e+05  1.706073e+09     106.260000  4.643524e+15   78501.000000   \n",
      "max    1.344214e+06  1.706764e+09   17620.830000  4.999601e+18   99921.000000   \n",
      "\n",
      "                 lat           long      city_pop      merch_lat  \\\n",
      "count  370703.000000  370703.000000  3.707030e+05  370703.000000   \n",
      "mean       37.528550     -92.158261  2.991079e+05      37.527942   \n",
      "std         5.282128      16.623988  5.644602e+05       5.313384   \n",
      "min        19.207900    -162.305600  1.040000e+02      18.210010   \n",
      "25%        33.851200     -99.103700  1.924000e+04      33.763643   \n",
      "50%        38.471800     -87.453200  6.381200e+04      38.371536   \n",
      "75%        41.230800     -80.063800  2.428030e+05      41.298640   \n",
      "max        64.854400     -67.040800  2.906700e+06      65.819961   \n",
      "\n",
      "          merch_long       is_fraud  \n",
      "count  370703.000000  370703.000000  \n",
      "mean      -92.158460       0.114105  \n",
      "std        16.632693       0.317939  \n",
      "min      -163.171646       0.000000  \n",
      "25%       -99.329107       0.000000  \n",
      "50%       -87.197353       0.000000  \n",
      "75%       -79.776034       0.000000  \n",
      "max       -66.249287       1.000000  \n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv('./data/train.csv')\n",
    "testingSet = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(\"train.csv shape is \", trainingSet.shape)\n",
    "print(\"test.csv shape is \", testingSet.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.head())\n",
    "print()\n",
    "print(testingSet.head())\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4129ea0-61bf-4701-8d91-ca6395c264e2",
   "metadata": {},
   "source": [
    "# Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "998f5d3d-92a0-46cd-9d93-cd03d06fd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to(df):\n",
    "    # This is where you can do all your feature extraction\n",
    "\n",
    "    # Label encode some of the categorical features\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    df['category_num'] = encoder.fit_transform(df['category'])\n",
    "    df['state_num'] = encoder.fit_transform(df['state'])\n",
    "    df['merchant_num'] = encoder.fit_transform(df['merchant'])\n",
    "    df['city_num'] = encoder.fit_transform(df['city'])\n",
    "    df['job_num'] = encoder.fit_transform(df['job'])\n",
    "    df['gender_num'] = encoder.fit_transform(df['gender'])\n",
    "    \n",
    "    # Calculate age of the person by using 'dob' column\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    \n",
    "    reference_date = datetime(2024, 12, 4) # pick a constant date for consistency in predictions\n",
    "    df['age'] = df['dob'].apply(lambda x: reference_date.year - x.year - ((reference_date.month, reference_date.day) < (x.month, x.day)))\n",
    "\n",
    "    \n",
    "    # Convert trans_date to datetime and extract components\n",
    "    df['trans_date'] = pd.to_datetime(df['trans_date'])\n",
    "    df['year'] = df['trans_date'].dt.year\n",
    "    df['month'] = df['trans_date'].dt.month\n",
    "    df['day'] = df['trans_date'].dt.day\n",
    "    \n",
    "    # Convert trans_time to datetime and extract components\n",
    "    df['trans_time'] = pd.to_datetime(df['trans_time'], format='%H:%M:%S').dt.time\n",
    "    df['hour'] = df['trans_time'].apply(lambda x: x.hour)\n",
    "    df['minute'] = df['trans_time'].apply(lambda x: x.minute)\n",
    "    df['second'] = df['trans_time'].apply(lambda x: x.second)\n",
    "\n",
    "    \n",
    "    # # Count unique merchants per day for each cardholder\n",
    "    # df['unique_merchants_per_day'] = df.groupby(['cc_num', df['trans_date'].dt.date])['merchant'].transform('nunique')\n",
    "    # # Count unique transaction categories per day for each cardholder\n",
    "    # df['unique_categories_per_day'] = df.groupby(['cc_num', df['trans_date'].dt.date])['category'].transform('nunique')\n",
    "\n",
    "    # historical_data = df.groupby('cc_num')[['category', 'merchant', 'amt']].apply(lambda x: x.mode().iloc[0]).to_dict()\n",
    "\n",
    "    # # Flag if the current transaction matches historical patterns\n",
    "    # df['percent_historical_similarity'] = df.apply(\n",
    "    #     lambda row: sum([\n",
    "    #         row['category'] == historical_data.get(row['cc_num'], {}).get('category', ''),\n",
    "    #         row['merchant'] == historical_data.get(row['cc_num'], {}).get('merchant', ''),\n",
    "    #         abs(row['amt'] - historical_data.get(row['cc_num'], {}).get('amt', 0)) < 5  # Small amount deviation\n",
    "    #     ]) / 3,\n",
    "    #     axis=1\n",
    "    # )\n",
    "\n",
    "    # df['common_merchants_with_others'] = df.groupby(['merchant', 'trans_date'])['cc_num'].transform('count')\n",
    "\n",
    "    # # Define a high-value threshold (e.g., 90th percentile)\n",
    "    # high_value_threshold = df['amt'].quantile(0.90)\n",
    "    # df['high_value'] = df['amt'] > high_value_threshold\n",
    "\n",
    "    # # Count high-value transactions per day for each cardholder\n",
    "    # df['high_value_transaction_count'] = df.groupby(['cc_num', df['trans_date'].dt.date])['amt'].transform(\n",
    "    #     lambda x: (x > high_value_threshold).sum()\n",
    "    # )\n",
    "    df['is_urban'] = df['city_pop'] > 50000\n",
    "    df['is_weekend'] = df['trans_date'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = add_features_to(trainingSet)\n",
    "X_submission = add_features_to(testingSet)\n",
    "\n",
    "# The training set is where the score is not null\n",
    "X_train =  X_train[X_train['is_fraud'].notnull()]\n",
    "\n",
    "X_submission.to_csv(\"./data/X_submission.csv\", index=False)\n",
    "X_train.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b861830-e6ab-4857-8c9e-b5da2ee138b7",
   "metadata": {},
   "source": [
    "# Sample + Split into Training & Testing Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e0c7c25b-b31a-44f7-b01f-eb347dd9607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train.drop(columns=['is_fraud']),\n",
    "    X_train['is_fraud'],\n",
    "    test_size=1/4.0,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6913841-ab99-4b5a-a2cd-daaddd61422f",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19c0f79f-43c4-4e85-ab39-bcff5d348474",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['amt', 'category_num', 'unix_time', 'gender_num', 'age', 'hour', 'day', 'is_urban', 'is_weekend']\n",
    "\n",
    "X_train_select = X_train[features]\n",
    "X_test_select = X_test[features]\n",
    "X_submission_select = X_submission[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd983419-7f05-4a11-9361-004608ea7914",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dcae20d5-1a10-42e6-987a-b26ea4396e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9788825757575758\n"
     ]
    }
   ],
   "source": [
    "# Select a model\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_iter=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_leaf_nodes=120,\n",
    "    min_samples_leaf=80,\n",
    "    random_state=42\n",
    ")\n",
    "# Fitting the model\n",
    "model.fit(X_train_select, Y_train)\n",
    "\n",
    "# Making predictions\n",
    "predictions = model.predict(X_test_select)\n",
    "print(\"F1 Score:\", f1_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4896763-47ba-46d5-9949-55570ccac16d",
   "metadata": {},
   "source": [
    "# Saving The File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4a721974-ebe5-4c9b-b413-4e5794205f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission file\n",
    "X_submission['is_fraud'] = model.predict(X_submission_select)\n",
    "submission = X_submission[['id', 'is_fraud']]\n",
    "submission.to_csv(\"./data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
